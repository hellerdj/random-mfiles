function [B,pY,SigmaHat,L,logmaxL,resdot] = mregress(Y,X)% function [B,pY,SigmaHat,L,logmaxL,resdot] = mregress(Y,X)%  Performs generalized multiple least squares regression.% The dependent variable, Y, is a matrix of N observations, each of % which is a k-tuple.  So analogous to standard regression in which % we write the equation y = Xb, % where y is the N x 1 column vector of observed dependent vars, % X is the N x M design matrix and b is the M x 1 column vector of% regression coefficients,%% we now write,% Y = XB. % Here Y is N x k, X is N x M, and B is M x k%% Often, the 1st column of X is ones(N,1)% In that case, the 1st row of B is the generalized intercept: % the expected vector when the independent variable is 0% e.g., int = [1 0 0 ... 0] * B%% The 2nd row is the vector offset for a unit change in the% independent variable% e.g., uvect = [1 1 0 ... 0]*B - int% % The routine returns the predicted vectors (pY) at the each of the% row-vector inputs in X.  It also returns values useful for computing% Likelihood ratios. SigmaHat is the maximum likelihood estimator of the% covariance matrix of the noise.  It's determinant is% known as the generalized variance. We return L, which is the% generalized variance raised the the N/2 power. This value can be used% to form a likelihood ratio in comparison to another (nested) model.% The return vector resdot are the residual vectors dotted on% themselves.  This is analogous to the square of the residuals, hence% useful for computing sum of squares.%% See T.W. Anderson, 2nd Ed. Chapter 8 (Sections 8.2 and 8.3) % 2/7/99 mns wrote it% 2/18/99 mns added max like estimator for Sigma and the likelihood% Test sizes [xrows xcols] = size(X);[yrows ycols] = size(Y);if xrows ~= yrows  error('X and Y must have the same number of rows')endA = (X'*X)';      % eq. 8C = (X'*Y)';B = (C*inv(A))';% Useful estimators for hypothesis testsn = size(X,1);pY = X*B;				% predicted valsSigmaHat = (Y'*Y - C*inv(A)*C') / n;	% Sec 8.2, eq 13L = det(SigmaHat) .^ (n/2);resdot = dot(Y-pY,Y-pY,2);% in Anderson, p is the dimension of the observation vectors% Compute the maximum likelihood Sec 8.3.1 eq 3 or 10p = xcols;logmaxL = (-p*n/2)*log(2*pi) + (-n/2)*log(det(SigmaHat)) - p*n/2;% Verification that this is the same as eq 12% $$$ shat = zeros(size(Y,2))% $$$ for i = 1:n% $$$   shat = shat + ((pY(i,:)-Y(i,:))' * (pY(i,:)-Y(i,:)));% $$$ end% $$$ shat = shat/n