function [p, d] = kstest(x1,x2,onedistflag)%  [p d] = kstest(x1,x2) performs Kolmogorov-Smirnov test of the hypothesis%  that the distribution of valuse in vectors x1 and x2 are different.  P is%  the probability of rejecting the null hypothesis of no difference between%  x1 and x2. This is Probability(D > observed) under the null hypothesis%  (eq. 14.3.9, Numerical Recipes in C, 2nd Ed., p. 624). d is the%  Kolmogorov-Smirnov d, observed.  IT is the maximum difference between the%  two cumulative distribution functions.% % kstest(x1,x2,onedistflag) performs the same test but setting onedistflag% to a nonempty value indicates that x2 is a theoretical distribution whose% values match those in x1 (observations).  The routine sets Ne to% the number of points in  x1. This is a good way to test for normality.% 1/20/97 mns wrote it% 2/1/97 mns added onedistflagq = [x1(:) ones(size(x1(:))); x2(:) zeros(size(x2(:)))];[y,I] =sort(q(:,1));y = q(I,:);% sum(y(:,2))n1 = length(x1);n2 = length(x2);c1 = cumsum(y(:,2))/n1;			% cum density for x1c2 = cumsum(~y(:,2))/n2;d = max(abs(c1-c2));				% K-S dif nargin<3  Ne = n1*n2/(n1+n2);else  Ne = n1;endlambda = d*(sqrt(Ne)+0.12 + (0.11/sqrt(Ne))); % argument in 14.3.9% pretty much guaranteed of converging with 100 terms -- overkill actuallyj=1:100;q = rem(j,2);qq = q-(~q);				% alternating 1,-1p = 2* sum(qq.*exp(-2 * j.*j * lambda * lambda));  % eq 14.3.7